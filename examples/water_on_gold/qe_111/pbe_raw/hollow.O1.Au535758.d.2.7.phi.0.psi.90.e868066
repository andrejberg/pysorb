[[58552,1],1][btl_openib_component.c:3496:handle_wc] from scc126 to: scc015 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 1d3d000 opcode 0  vendor error 129 qp_idx 2
[[58552,1],2][btl_openib_component.c:3496:handle_wc] from scc126 to: scc015 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 246d900 opcode 1  vendor error 129 qp_idx 2
[[58552,1],3][btl_openib_component.c:3496:handle_wc] from scc126 to: scc015 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 262a480 opcode 128  vendor error 129 qp_idx 2
--------------------------------------------------------------------------
The InfiniBand retry count between two MPI processes has been
exceeded.  "Retry count" is defined in the InfiniBand spec 1.2
(section 12.7.38):

    The total number of times that the sender wishes the receiver to
    retry timeout, packet sequence, etc. errors before posting a
    completion error.

This error typically means that there is something awry within the
InfiniBand fabric itself.  You should note the hosts on which this
error has occurred; it has been observed that rebooting or removing a
particular host from the job can sometimes resolve this issue.  

Two MCA parameters can be used to control Open MPI's behavior with
respect to the retry count:

* btl_openib_ib_retry_count - The number of times the sender will
  attempt to retry (defaulted to 7, the maximum value).
* btl_openib_ib_timeout - The local ACK timeout parameter (defaulted
  to 20).  The actual timeout value used is calculated as:

     4.096 microseconds * (2^btl_openib_ib_timeout)

  See the InfiniBand spec 1.2 (section 12.7.34) for more details.

Below is some information about the host that raised the error and the
peer to which it was connected:

  Local host:   scc126
  Local device: mlx4_0
  Peer host:    scc015

You may need to consult with your system administrator to get this
problem fixed.
--------------------------------------------------------------------------
[scc126:09561] 2 more processes have sent help message help-mpi-btl-openib.txt / pp retry exceeded
[scc126:09561] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[[58552,1],23][btl_openib_component.c:3496:handle_wc] from scc015 to: scc026 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 1debb00 opcode 2  vendor error 129 qp_idx 2
[[58552,1],22][btl_openib_component.c:3496:handle_wc] from scc015 to: scc026 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 2497f80 opcode 2  vendor error 129 qp_idx 2
[[58552,1],21][btl_openib_component.c:3496:handle_wc] from scc015 to: scc026 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 22a4800 opcode 2  vendor error 129 qp_idx 2
[[58552,1],20][btl_openib_component.c:3496:handle_wc] from scc015 to: scc026 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 1d5bf80 opcode 2  vendor error 129 qp_idx 2
[[58552,1],18][btl_openib_component.c:3496:handle_wc] from scc015 to: scc026 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 221bb00 opcode 2  vendor error 129 qp_idx 2
[[58552,1],19][btl_openib_component.c:3496:handle_wc] from scc015 to: scc026 error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 1cb7980 opcode 2  vendor error 129 qp_idx 2
--------------------------------------------------------------------------
WARNING: A process refused to die!

Host: scc015
PID:  21199

This process may still be running and/or consuming resources.

--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 2 with PID 9573 on
node scc126 exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
The OpenFabrics stack has reported a network error event.  Open MPI
will try to continue, but your job may end up failing.

  Local host:        ‘Ñ
  MPI process PID:   21216
  Error number:      10 (IBV_EVENT_PORT_ERR)

This error may indicate connectivity problems within the fabric;
please contact your system administrator.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
The OpenFabrics stack has reported a network error event.  Open MPI
will try to continue, but your job may end up failing.

  Local host:        scc015
  MPI process PID:   21200
  Error number:      10 (IBV_EVENT_PORT_ERR)

This error may indicate connectivity problems within the fabric;
please contact your system administrator.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
The OpenFabrics stack has reported a network error event.  Open MPI
will try to continue, but your job may end up failing.

  Local host:        ê¯2
  MPI process PID:   21217
  Error number:      10 (IBV_EVENT_PORT_ERR)

This error may indicate connectivity problems within the fabric;
please contact your system administrator.
--------------------------------------------------------------------------
fatal flex scanner internal error--end of buffer missed

Program received signal SIGSEGV: Segmentation fault - invalid memory reference.

Backtrace for this error:
#0  0x2b7ca38845be
#1  0x2b7ca3884cc4
#2  0x2b7ca4d4a0df
#3  0x2b7ca33a3996
#4  0x2b7ca33a26dc
#5  0x2b7ca333568c
#6  0x2b7ca862266c
#7  0x2b7ca8622c98
#8  0x2b7ca339bbf9
#9  0x2b7ca32eb06c
#10  0x2b7ca9afbc43
#11  0x2b7ca9b000f3
#12  0x2b7ca32f7005
#13  0x2b7ca3073029
#14  0x66df6f
#15  0x6740cd
#16  0x6719eb
#17  0x633095
#18  0x5fc5ed
#19  0x5b1a1f
#20  0x59e6d8
#21  0x59f6bb
#22  0x489176
#23  0x48d41c
#24  0x439f4b
#25  0x439c84
#26  0x2b7ca4d36a14
#27  0x439cd0
#28  0xffffffffffffffff

Program received signal SIGSEGV: Segmentation fault - invalid memory reference.

Backtrace for this error:
#0  0x2b100904b5be
#1  0x2b100904bcc4
#2  0x2b100a5110df
#3  0x2b1008b6af2e
#4  0x2b1008b696dc
#5  0x2b1008afc68c
#6  0x2b100ddf3343
#7  0x2b100a2c7e0e
#8  0x2b100a5c50dc
#9  0xffffffffffffffff
fatal flex scanner internal error--end of buffer missed
[scc126:09561] 4 more processes have sent help message help-mpi-btl-openib.txt / pp retry exceeded
[scc126:09561] 2 more processes have sent help message help-odls-default.txt / odls-default:could-not-kill
[scc126:09561] 24 more processes have sent help message help-mpi-btl-openib.txt / of error event
